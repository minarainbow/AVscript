<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>AVscript: Accessible Video Editing with Audio-Visual Scripts</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title publication-title">AVscript: Accessible Video Editing with Audio-Visual Scripts</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
                <span class="author-block">
                  <a href="http://www.minahuh.com" target="_blank">Mina Huh</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a href="https://www.saelyne.com/" target="_blank">Saelyne Yang</a><sup>3</sup>,</span>
                <span class="author-block">
                  <a href="https://www.yihaopeng.tw/" target="_blank">Yi-Hao Peng</a><sup>4</sup>,</span>
                <span class="author-block">
                  <a href="https://xac.is/" target="_blank">Xiang 'Anthony' Chen</a><sup>5</sup>,</span>
                <span class="author-block">
                  <a href="http://younghokim.net/" target="_blank">Young-Ho Kim</a><sup>2</sup>,</span>
                <span class="author-block">
                  <a href="http://www.amypavel.com" target="_blank">Amy Pavel</a><sup>1</sup>,</span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">UT Austin<sup>1</sup>, Naver AI<sup>2</sup>, KAIST<sup>3</sup>, CMU<sup>4</sup>, UCLA<sup>5</sup><br>ACM CHI 2023</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://dl.acm.org/doi/10.1145/3544548.3581494" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2302.14117" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.jpg" />
      <h2 class="subtitle has-text-centered">
        <b>AVscript</b> is an accessible text-based video editing tool that enables blind and low-vision creators to edit videos
        efficiently using a screen reader. The <b>audio-visual script</b> provides a narration transcript segmented by scenes, scene descriptions, and highlighted visual errors (<i>e.g.,</i> blur, bad lighting).
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Sighted and blind and low vision (BLV) creators alike use videos to communicate with broad audiences. 
            Yet, video editing remains inaccessible to BLV creators.
            Our formative study revealed that current video editing tools make it difficult to access the visual content, assess the visual quality, and efficiently navigate the timeline.
            We present AVscript, an accessible text-based video editor. AVscript enables users to edit their video using a script that embeds the video's visual content, visual errors (<i>e.g.</i>, dark or blurred footage), and speech. Users can also efficiently navigate between scenes and visual errors or locate objects in the frame or spoken words of interest.
            A comparison study (N=12) showed that AVscript significantly lowered BLV creators' mental demands while increasing confidence and independence in video editing. We further demonstrate the potential of AVscript through an exploratory study (N=3) where BLV creators edited their own footage.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">System</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <img src="static/images/video-pane.jpg" width="50%"/>
      <h2 class="subtitle has-text-centered">
        AVscript’s video pane provides two types of audio notifications: scene change notifications and visual error notifications. When paused, users can activate inspect mode to access
        detected objects in the current frame.
      </h2>
      <br><br><hr style="height: 1.2px; background-color: lightgray;"><br><br>
      <img src="static/images/outline.jpg" width="70%"/>
      <h2 class="subtitle has-text-centered">
        AVscript’s outline pane displays a navigable summary of the audio-visual script including the high-level
        scenes and potential edit points, such as pauses and visual errors.
      </h2>
      <br><br><hr style="height: 1.2px; background-color: lightgray;"><br><br>
      <img src="static/images/search.jpg" width="60%"/>
      <h2 class="subtitle has-text-centered">
        AVscript supports search over the transcribed
        speech and visual objects in the video. BLV creators can skim
        the results and click on a search result to jump to the corresponding point in the video.
      </h2>
        </div>
      </div>
    </div>
  </div>
</section>

<hr style="height: 1.2px; background-color: lightgray;">

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Pipeline</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <img src="static/images/pipeline.jpg" />
      <h2 class="subtitle has-text-centered">
        To segment the footage into multiple scenes, we detect objects in each frame using the nouns extracted from the transcript
        as custom vocabulary. Then, we segment the footage when there is a salient change in the objects detected in nearby frames.
        For each scene, we caption the first non-blurry frame, then use as the scene’s title in the audio-visual script.
      </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<hr style="height: 1.2px; background-color: lightgray;">

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Evaluation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <img src="static/images/evaluation.jpg" width="70%" style="margin-right: 20%;"/>
          <h2 class="subtitle has-text-centered">
            After the video editing tasks, we measured the cognitive load using NASA-TLX. AVscript significantly outperformed users’ own video editing tools in mental demand, temporal demand, effort, and frustration.
            AVscript was also rated significantly better in the confidence in the output, independence in reviewing output, and
            helpfulness in identifying errors.
        </h2>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/Hj9sQrULzw4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{10.1145/3544548.3581494,
        author = {Huh, Mina and Yang, Saelyne and Peng, Yi-Hao and Chen, Xiang 'Anthony' and Kim, Young-Ho and Pavel, Amy},
        title = {AVscript: Accessible Video Editing with Audio-Visual Scripts},
        year = {2023},
        isbn = {9781450394215},
        publisher = {Association for Computing Machinery},
        address = {New York, NY, USA},
        url = {https://doi.org/10.1145/3544548.3581494},
        doi = {10.1145/3544548.3581494},
        abstract = {Sighted and blind and low vision (BLV) creators alike use videos to communicate with broad audiences. Yet, video editing remains inaccessible to BLV creators. Our formative study revealed that current video editing tools make it difficult to access the visual content, assess the visual quality, and efficiently navigate the timeline. We present &nbsp;AVscript, an accessible text-based video editor. &nbsp;AVscript enables users to edit their video using a script that embeds the video’s visual content, visual errors (e.g., dark or blurred footage), and speech. Users can also efficiently navigate between scenes and visual errors or locate objects in the frame or spoken words of interest. A comparison study (N=12) showed that &nbsp;AVscript significantly lowered BLV creators’ mental demands while increasing confidence and independence in video editing. We further demonstrate the potential of &nbsp;AVscript through an exploratory study (N=3) where BLV creators edited their own footage.},
        booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
        articleno = {796},
        numpages = {17},
        keywords = {video, accessibility, authoring tools},
        location = {Hamburg, Germany},
        series = {CHI '23}
        }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
